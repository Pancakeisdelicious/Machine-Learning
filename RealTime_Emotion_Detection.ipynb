{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTime-Emotion-Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10gxNyrtjMuu7JbQ2y4hP2BKqto_NRjZm",
      "authorship_tag": "ABX9TyNQoVloQZ4rXFURFWDqhD+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pancakeisdelicious/Machine-Learning/blob/main/RealTime_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej3ipKd3gzS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df050c51-1c94-49cf-81eb-3b02ea9b8449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Epoch 1/200\n",
            "449/449 [==============================] - 366s 814ms/step - loss: 1.7065 - accuracy: 0.2987 - val_loss: 1.5397 - val_accuracy: 0.3812\n",
            "Epoch 2/200\n",
            "449/449 [==============================] - 360s 802ms/step - loss: 1.4846 - accuracy: 0.4177 - val_loss: 1.4883 - val_accuracy: 0.4205\n",
            "Epoch 3/200\n",
            "449/449 [==============================] - 359s 800ms/step - loss: 1.3829 - accuracy: 0.4648 - val_loss: 1.3131 - val_accuracy: 0.4820\n",
            "Epoch 4/200\n",
            "449/449 [==============================] - 359s 800ms/step - loss: 1.3213 - accuracy: 0.4892 - val_loss: 1.2874 - val_accuracy: 0.4937\n",
            "Epoch 5/200\n",
            "449/449 [==============================] - 357s 795ms/step - loss: 1.2754 - accuracy: 0.5098 - val_loss: 1.2282 - val_accuracy: 0.5274\n",
            "Epoch 6/200\n",
            "449/449 [==============================] - 357s 795ms/step - loss: 1.2401 - accuracy: 0.5249 - val_loss: 1.2131 - val_accuracy: 0.5269\n",
            "Epoch 7/200\n",
            "449/449 [==============================] - 356s 793ms/step - loss: 1.2141 - accuracy: 0.5355 - val_loss: 1.2050 - val_accuracy: 0.5417\n",
            "Epoch 8/200\n",
            "449/449 [==============================] - 356s 793ms/step - loss: 1.1911 - accuracy: 0.5435 - val_loss: 1.2176 - val_accuracy: 0.5255\n",
            "Epoch 9/200\n",
            "449/449 [==============================] - 356s 794ms/step - loss: 1.1633 - accuracy: 0.5567 - val_loss: 1.1661 - val_accuracy: 0.5589\n",
            "Epoch 10/200\n",
            "449/449 [==============================] - 357s 795ms/step - loss: 1.1413 - accuracy: 0.5653 - val_loss: 1.1610 - val_accuracy: 0.5559\n",
            "Epoch 11/200\n",
            "449/449 [==============================] - 361s 805ms/step - loss: 1.1240 - accuracy: 0.5678 - val_loss: 1.1619 - val_accuracy: 0.5709\n",
            "Epoch 12/200\n",
            "449/449 [==============================] - 361s 804ms/step - loss: 1.1047 - accuracy: 0.5807 - val_loss: 1.1508 - val_accuracy: 0.5659\n",
            "Epoch 13/200\n",
            "449/449 [==============================] - 358s 798ms/step - loss: 1.0902 - accuracy: 0.5859 - val_loss: 1.1522 - val_accuracy: 0.5631\n",
            "Epoch 14/200\n",
            "449/449 [==============================] - 358s 796ms/step - loss: 1.0713 - accuracy: 0.5890 - val_loss: 1.1834 - val_accuracy: 0.5453\n",
            "Epoch 15/200\n",
            "449/449 [==============================] - 361s 803ms/step - loss: 1.0623 - accuracy: 0.5943 - val_loss: 1.1529 - val_accuracy: 0.5662\n",
            "Epoch 16/200\n",
            " 90/449 [=====>........................] - ETA: 4:38 - loss: 1.0224 - accuracy: 0.6003"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('gdrive/My Drive/fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")\n",
        "\n"
      ]
    }
  ]
}